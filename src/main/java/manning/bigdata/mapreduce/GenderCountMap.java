package manning.bigdata.mapreduce;


import com.backtype.hadoop.pail.SequenceFileFormat;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.PathFilter;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.TextOutputFormat;

/**
 * User: ivaramme
 * Date: 7/25/14
 *
 * Maps are the individual tasks that transform input records into intermediate records. The transformed intermediate
 * records do not need to be of the same type as the input records. A given input pair may map to zero or many output pairs.
 */
public class GenderCountMap {

    public static void main(String[] args) throws Exception {
        String hdfsURL;
        try {
            hdfsURL = System.getenv("HDFS_URL");
        } catch (Exception e) {
            throw new RuntimeException("Invalid hdfs Path");
        }

        JobConf conf = new JobConf(GenderMap.class);
        conf.setJobName("genderCount");
        conf.setOutputKeyClass(Text.class);
        conf.setOutputValueClass(IntWritable.class);

        conf.setMapperClass(GenderMap.class);
        conf.setCombinerClass(GenderReduce.class);
        conf.setReducerClass(GenderReduce.class);

        conf.setInputFormat(SequenceFileFormat.SequenceFilePailInputFormat.class);
        conf.setOutputFormat(TextOutputFormat.class);

        // Split data files
        // **********************************************************
        // Using SequenceFileInputFormat as this is binary content
        // TODO: need to fix this: The SequenceFilePailInputFormat doesn't go through child directories contrary
        // to what SequenceFileInputFormat does (you can point to the parent directory and the the * wildcard to
        // explore all subdirectories)
        // **********************************************************
        SequenceFileFormat.SequenceFilePailInputFormat.setInputPathFilter(conf, PailFilter.class);
        SequenceFileFormat.SequenceFilePailInputFormat.setInputPaths(conf, new Path(hdfsURL + "/tmp/storm-test/201408140013")); // '*' is needed to go inside subdirectories
        FileOutputFormat.setOutputPath(conf, new Path(hdfsURL + "/tmp/output/"+System.currentTimeMillis()));

        JobClient.runJob(conf);

    }
}

// Filter to select the data files generated by pail
class PailFilter extends Configured implements PathFilter {

    @Override
    public boolean accept(Path path) {
        if(path.getName().endsWith("data"))
            return false;

        System.out.println(path);
        return true;
    }
}